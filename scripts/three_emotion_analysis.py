#!/usr/bin/env python3
"""
ä¸‰æƒ…ç»ªAUç‰¹å¾å¯¹æ¯”åˆ†æè„šæœ¬
æ•°æ®: OpenFace 2.0 è¾“å‡º (AUå¼ºåº¦å€¼)
å¯¹æ¯”: æ‚²ä¼¤ vs é£æ™¯(ä¸­æ€§) vs æ­£æ€§
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import f_oneway, kruskal
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®å›¾å½¢æ ·å¼
plt.style.use('default')
sns.set_palette("husl")

# ============ é…ç½®è·¯å¾„å’Œæƒ…ç»ªæ ‡ç­¾ ============
# è¯·æ ¹æ®å®é™…æ–‡ä»¶ä¿®æ”¹ä»¥ä¸‹é…ç½®
FILE_CONFIG = {
    'æ‚²ä¼¤': '/root/.openclaw/media/inbound/file_3---b3314058-964d-470d-8293-13430fdde2c6.csv',
    'é£æ™¯': '/root/.openclaw/media/inbound/file_4---0dd96eb3-72ff-4ced-a1b8-c5c51fad721a.csv',
    'æ­£æ€§': '/root/.openclaw/media/inbound/file_5---69ad20a2-5a2f-4f18-bdef-056d8c24d515.csv'
}

# æƒ…ç»ªé¢œè‰²æ–¹æ¡ˆ
EMOTION_COLORS = {
    'æ‚²ä¼¤': '#3498db',  # è“è‰²
    'é£æ™¯': '#95a5a6',  # ç°è‰²
    'æ­£æ€§': '#e74c3c'   # çº¢è‰²
}

# æ ¸å¿ƒAUåˆ—è¡¨ (æ’é™¤ _c åˆ—ï¼Œåªä¿ç•™å¼ºåº¦å€¼ _r)
CORE_AU = ['AU01_r', 'AU02_r', 'AU04_r', 'AU05_r', 'AU06_r', 'AU07_r', 
           'AU09_r', 'AU10_r', 'AU12_r', 'AU14_r', 'AU15_r', 'AU17_r', 
           'AU20_r', 'AU23_r', 'AU25_r', 'AU26_r', 'AU45_r']

def load_and_preprocess(filepath, emotion_label):
    """åŠ è½½æ•°æ®å¹¶é¢„å¤„ç†"""
    df = pd.read_csv(filepath)
    
    # æ¸…ç†åˆ—åï¼ˆå»é™¤ç©ºæ ¼ï¼‰
    df.columns = df.columns.str.strip()
    
    # åªä¿ç•™æˆåŠŸæ£€æµ‹çš„å¸§
    df = df[df['success'] == 1]
    df = df[df['confidence'] >= 0.95]  # é«˜ç½®ä¿¡åº¦
    
    # æ·»åŠ æƒ…ç»ªæ ‡ç­¾
    df['emotion'] = emotion_label
    
    return df

def cohen_d(x, y):
    """è®¡ç®—Cohen's dæ•ˆåº”é‡"""
    nx = len(x)
    ny = len(y)
    dof = nx + ny - 2
    return (np.mean(x) - np.mean(y)) / np.sqrt(
        ((nx-1)*np.std(x, ddof=1)**2 + (ny-1)*np.std(y, ddof=1)**2) / dof
    )

def perform_anova(data_dict, au_column):
    """æ‰§è¡Œå•å› ç´ ANOVA"""
    groups = [df[au_column].values for df in data_dict.values()]
    f_stat, p_value = f_oneway(*groups)
    return f_stat, p_value

def perform_kruskal(data_dict, au_column):
    """æ‰§è¡ŒKruskal-Wallisæ£€éªŒï¼ˆéå‚æ•°ï¼‰"""
    groups = [df[au_column].values for df in data_dict.values()]
    h_stat, p_value = kruskal(*groups)
    return h_stat, p_value

def bonferroni_posthoc(data_dict, au_column, alpha=0.05):
    """Bonferroniæ ¡æ­£äº‹åæ£€éªŒ"""
    emotions = list(data_dict.keys())
    n_comparisons = len(emotions) * (len(emotions) - 1) // 2
    corrected_alpha = alpha / n_comparisons
    
    results = []
    for i in range(len(emotions)):
        for j in range(i+1, len(emotions)):
            group1 = data_dict[emotions[i]][au_column].values
            group2 = data_dict[emotions[j]][au_column].values
            
            # tæ£€éªŒ
            t_stat, p_val = stats.ttest_ind(group1, group2)
            
            # æ•ˆåº”é‡
            effect = cohen_d(group1, group2)
            
            results.append({
                'comparison': f"{emotions[i]} vs {emotions[j]}",
                't_stat': t_stat,
                'p_value': p_val,
                'p_corrected': p_val * n_comparisons,
                'significant': p_val < corrected_alpha,
                'cohens_d': effect,
                'effect_size': 'Large' if abs(effect) >= 0.8 else ('Medium' if abs(effect) >= 0.5 else 'Small')
            })
    
    return pd.DataFrame(results)

# ============ ä¸»ç¨‹åº ============
print("=" * 70)
print("OpenFace AUæƒ…ç»ªç‰¹å¾å¯¹æ¯”åˆ†æ")
print("=" * 70)

# 1. åŠ è½½æ•°æ®
print("\nğŸ“‚ åŠ è½½æ•°æ®æ–‡ä»¶...")
data_dict = {}
for emotion, filepath in FILE_CONFIG.items():
    df = load_and_preprocess(filepath, emotion)
    data_dict[emotion] = df
    print(f"  {emotion}: {len(df)} å¸§ (ç½®ä¿¡åº¦â‰¥0.95)")

# 2. æè¿°æ€§ç»Ÿè®¡
print("\n" + "=" * 70)
print("ğŸ“Š æè¿°æ€§ç»Ÿè®¡ (AUå¹³å‡å¼ºåº¦ Â± æ ‡å‡†å·®)")
print("=" * 70)

desc_stats = []
for emotion, df in data_dict.items():
    stats_row = {'Emotion': emotion, 'N_Frames': len(df)}
    for au in CORE_AU:
        stats_row[f"{au}_mean"] = df[au].mean()
        stats_row[f"{au}_std"] = df[au].std()
    desc_stats.append(stats_row)

desc_df = pd.DataFrame(desc_stats)

# æ‰“å°ä¸»è¦AUçš„å‡å€¼
print("\nä¸»è¦AUå¼ºåº¦å¯¹æ¯”:")
main_au_display = ['AU04_r', 'AU06_r', 'AU07_r', 'AU12_r', 'AU15_r', 'AU25_r']
for au in main_au_display:
    print(f"\n{au}:")
    for _, row in desc_df.iterrows():
        mean_val = row[f"{au}_mean"]
        std_val = row[f"{au}_std"]
        print(f"  {row['Emotion']:6s}: {mean_val:.3f} Â± {std_val:.3f}")

# 3. ç»„é—´å·®å¼‚æ£€éªŒ
print("\n" + "=" * 70)
print("ğŸ“ˆ ç»„é—´å·®å¼‚æ£€éªŒ (ANOVA)")
print("=" * 70)

anova_results = []
for au in CORE_AU:
    f_stat, p_val = perform_anova(data_dict, au)
    anova_results.append({
        'AU': au,
        'F_statistic': f_stat,
        'p_value': p_val,
        'significant': p_val < 0.05,
        'significant_bonferroni': p_val < (0.05 / len(CORE_AU))  # Bonferroniæ ¡æ­£
    })

anova_df = pd.DataFrame(anova_results)
anova_df = anova_df.sort_values('p_value')

print("\næ˜¾è‘—çš„AUå·®å¼‚ (p < 0.05):")
sig_au = anova_df[anova_df['significant']]
if len(sig_au) > 0:
    for _, row in sig_au.head(10).iterrows():
        sig_marker = "***" if row['significant_bonferroni'] else "**" if row['p_value'] < 0.01 else "*"
        print(f"  {row['AU']:8s}: F={row['F_statistic']:6.2f}, p={row['p_value']:.4f} {sig_marker}")
else:
    print("  æ— æ˜¾è‘—å·®å¼‚")

# 4. äº‹åæ£€éªŒ (å¯¹æœ€æ˜¾è‘—çš„AU)
print("\n" + "=" * 70)
print("ğŸ” äº‹åæ£€éªŒ (Bonferroniæ ¡æ­£) - æœ€æ˜¾è‘—çš„AU")
print("=" * 70)

if len(sig_au) > 0:
    top_au = sig_au.iloc[0]['AU']
    print(f"\n{top_au} çš„ç»„é—´å¯¹æ¯”:")
    posthoc = bonferroni_posthoc(data_dict, top_au)
    for _, row in posthoc.iterrows():
        sig = "***" if row['significant'] else ""
        print(f"  {row['comparison']:15s}: t={row['t_stat']:6.2f}, "
              f"p={row['p_value']:.4f}, Cohen's d={row['cohens_d']:.3f} "
              f"({row['effect_size']}) {sig}")

# 5. å¯è§†åŒ–
print("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")

fig = plt.figure(figsize=(20, 24))

# 5.1 å„æƒ…ç»ªAUå¹³å‡å¼ºåº¦æŸ±çŠ¶å›¾
ax1 = plt.subplot(4, 2, 1)
x_pos = np.arange(len(CORE_AU))
width = 0.25

for i, (emotion, df) in enumerate(data_dict.items()):
    means = [df[au].mean() for au in CORE_AU]
    sems = [df[au].sem() for au in CORE_AU]  # æ ‡å‡†è¯¯
    ax1.bar(x_pos + i*width, means, width, yerr=sems, 
            label=emotion, color=EMOTION_COLORS[emotion], alpha=0.8, capsize=3)

ax1.set_xlabel('Action Units', fontsize=11)
ax1.set_ylabel('Mean Intensity', fontsize=11)
ax1.set_title('AU Mean Intensity by Emotion (Â± SEM)', fontsize=13, fontweight='bold')
ax1.set_xticks(x_pos + width)
ax1.set_xticklabels([au.replace('_r', '') for au in CORE_AU], rotation=45, ha='right')
ax1.legend()
ax1.grid(axis='y', alpha=0.3)

# 5.2 ç®±çº¿å›¾å¯¹æ¯”
ax2 = plt.subplot(4, 2, 2)
plot_data = []
plot_labels = []
for emotion, df in data_dict.items():
    # é€‰æ‹©å‡ ä¸ªå…³é”®AU
    for au in ['AU04_r', 'AU06_r', 'AU12_r', 'AU25_r']:
        plot_data.extend(df[au].values)
        plot_labels.extend([f"{emotion}\n{au}"] * len(df))

box_df = pd.DataFrame({'Value': plot_data, 'Group': plot_labels})
sns.boxplot(data=box_df, x='Group', y='Value', ax=ax2, palette='Set2')
ax2.set_title('Key AU Distribution by Emotion', fontsize=13, fontweight='bold')
ax2.set_xlabel('')
ax2.tick_params(axis='x', rotation=45)

# 5.3 æ‚²ä¼¤æƒ…ç»ªAUç›¸å…³æ€§çƒ­å›¾
ax3 = plt.subplot(4, 3, 7)
sad_corr = data_dict['æ‚²ä¼¤'][CORE_AU].corr()
sns.heatmap(sad_corr, annot=True, fmt='.2f', cmap='RdBu_r', center=0,
            square=True, ax=ax3, cbar_kws={'shrink': 0.8}, annot_kws={'size': 7})
ax3.set_title('Sad - AU Correlation', fontsize=12, fontweight='bold')

# 5.4 é£æ™¯æƒ…ç»ªAUç›¸å…³æ€§çƒ­å›¾
ax4 = plt.subplot(4, 3, 8)
neu_corr = data_dict['é£æ™¯'][CORE_AU].corr()
sns.heatmap(neu_corr, annot=True, fmt='.2f', cmap='RdBu_r', center=0,
            square=True, ax=ax4, cbar_kws={'shrink': 0.8}, annot_kws={'size': 7})
ax4.set_title('Neutral - AU Correlation', fontsize=12, fontweight='bold')

# 5.5 æ­£æ€§æƒ…ç»ªAUç›¸å…³æ€§çƒ­å›¾
ax5 = plt.subplot(4, 3, 9)
pos_corr = data_dict['æ­£æ€§'][CORE_AU].corr()
sns.heatmap(pos_corr, annot=True, fmt='.2f', cmap='RdBu_r', center=0,
            square=True, ax=ax5, cbar_kws={'shrink': 0.8}, annot_kws={'size': 7})
ax5.set_title('Positive - AU Correlation', fontsize=12, fontweight='bold')

# 5.6 ä¸‰æƒ…ç»ªç›¸å…³æ€§å·®å¼‚å¯¹æ¯”
ax6 = plt.subplot(4, 2, 5)
# è®¡ç®—ç›¸å…³ç³»æ•°å·®å¼‚
diff_corr = sad_corr - pos_corr
sns.heatmap(diff_corr, annot=True, fmt='.2f', cmap='RdBu_r', center=0,
            square=True, ax=ax6, cbar_kws={'shrink': 0.8}, annot_kws={'size': 7})
ax6.set_title('Sad vs Positive (Correlation Difference)', fontsize=12, fontweight='bold')

# 5.7 æƒ…ç»ªæ—¶é—´åºåˆ—å¯¹æ¯” (ä»¥AU12ä¸ºä¾‹)
ax7 = plt.subplot(4, 2, 6)
for emotion, df in data_dict.items():
    # å½’ä¸€åŒ–æ—¶é—´ (0-100%)
    time_norm = np.linspace(0, 100, len(df))
    # å¹³æ»‘æ›²çº¿
    from scipy.ndimage import uniform_filter1d
    au12_smooth = uniform_filter1d(df['AU12_r'].values, size=10)
    ax7.plot(time_norm, au12_smooth, label=emotion, 
             color=EMOTION_COLORS[emotion], linewidth=2)
ax7.set_xlabel('Time (%)', fontsize=11)
ax7.set_ylabel('AU12 Intensity (Lip Corner Puller)', fontsize=11)
ax7.set_title('AU12 Time Course by Emotion', fontsize=13, fontweight='bold')
ax7.legend()
ax7.grid(alpha=0.3)

# 5.8 é›·è¾¾å›¾ - æƒ…ç»ªç‰¹å¾è½®å»“
ax8 = plt.subplot(4, 2, 7, projection='polar')
key_au = ['AU04_r', 'AU06_r', 'AU07_r', 'AU12_r', 'AU15_r', 'AU25_r']
angles = np.linspace(0, 2*np.pi, len(key_au), endpoint=False).tolist()
angles += angles[:1]  # é—­åˆ

for emotion, df in data_dict.items():
    values = [df[au].mean() for au in key_au]
    values += values[:1]  # é—­åˆ
    ax8.plot(angles, values, 'o-', linewidth=2, label=emotion, 
             color=EMOTION_COLORS[emotion])
    ax8.fill(angles, values, alpha=0.15, color=EMOTION_COLORS[emotion])

ax8.set_xticks(angles[:-1])
ax8.set_xticklabels([au.replace('_r', '') for au in key_au])
ax8.set_title('Emotion Profile (Radar)', fontsize=13, fontweight='bold', pad=20)
ax8.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))

# 5.9 Få€¼çƒ­å›¾ (æ˜¾è‘—æ€§)
ax9 = plt.subplot(4, 2, 8)
f_values = anova_df.set_index('AU')['F_statistic'].values.reshape(1, -1)
im = ax9.imshow(f_values, cmap='YlOrRd', aspect='auto')
ax9.set_xticks(range(len(CORE_AU)))
ax9.set_xticklabels([au.replace('_r', '') for au in CORE_AU], rotation=45, ha='right')
ax9.set_yticks([0])
ax9.set_yticklabels(['F-statistic'])
ax9.set_title('ANOVA F-statistic by AU', fontsize=13, fontweight='bold')
plt.colorbar(im, ax=ax9)

# æ·»åŠ æ˜¾è‘—æ€§æ ‡è®°
for i, (_, row) in enumerate(anova_df.iterrows()):
    if row['significant_bonferroni']:
        ax9.text(i, 0, '***', ha='center', va='center', fontsize=12, color='white', fontweight='bold')
    elif row['p_value'] < 0.01:
        ax9.text(i, 0, '**', ha='center', va='center', fontsize=12, color='white', fontweight='bold')
    elif row['p_value'] < 0.05:
        ax9.text(i, 0, '*', ha='center', va='center', fontsize=12, color='white', fontweight='bold')

plt.tight_layout()
plt.savefig('three_emotion_au_analysis.png', dpi=300, bbox_inches='tight')
print("  âœ… å›¾è¡¨å·²ä¿å­˜: three_emotion_au_analysis.png")

# 6. ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
print("\n" + "=" * 70)
print("ğŸ“‹ è¯¦ç»†åˆ†ææŠ¥å‘Š")
print("=" * 70)

report = f"""
ã€OpenFace AUä¸‰æƒ…ç»ªå¯¹æ¯”åˆ†ææŠ¥å‘Šã€‘

1. æ•°æ®æ¦‚å†µ:
   - åˆ†æå¯¹è±¡: OpenFace 2.0æå–çš„17ä¸ªAUå¼ºåº¦å€¼
   - æƒ…ç»ªç±»å‹: æ‚²ä¼¤ã€é£æ™¯(ä¸­æ€§)ã€æ­£æ€§
   - å¸§æ•°ç»Ÿè®¡:
"""
for emotion, df in data_dict.items():
    report += f"     * {emotion:4s}: {len(df):4d} å¸§\n"

report += f"""
2. æ ¸å¿ƒå‘ç°:
   
   A. æœ€å…·åŒºåˆ†åº¦çš„AU (åŸºäºANOVA Få€¼):
"""

for _, row in anova_df.head(5).iterrows():
    sig = "***" if row['significant_bonferroni'] else "**" if row['p_value'] < 0.01 else ("*" if row['p_value'] < 0.05 else "")
    report += f"      - {row['AU']:8s}: F={row['F_statistic']:7.2f}, p={row['p_value']:.4f} {sig}\n"

report += f"""
   B. æƒ…ç»ªç‰¹å¼‚æ€§AUæ¨¡å¼:
"""

# è®¡ç®—æ¯ä¸ªæƒ…ç»ªæœ€æ´»è·ƒçš„AU
for emotion, df in data_dict.items():
    top_au = df[CORE_AU].mean().sort_values(ascending=False).head(3)
    report += f"      {emotion}æƒ…ç»ª Top 3 AU:\n"
    for au, val in top_au.items():
        report += f"        - {au}: {val:.3f}\n"
    report += "\n"

report += f"""
3. ç»Ÿè®¡æ£€éªŒè¯´æ˜:
   - ANOVAç”¨äºæ£€éªŒä¸‰ç»„é—´å·®å¼‚
   - Bonferroniæ ¡æ­£: Î± = 0.05/{len(CORE_AU)} = {0.05/len(CORE_AU):.4f}
   - æ•ˆåº”é‡: Cohen's d (Small: 0.2, Medium: 0.5, Large: 0.8)

4. å¯è§†åŒ–è¾“å‡º:
   - three_emotion_au_analysis.png (ç»¼åˆåˆ†æå›¾)
"""

print(report)

# ä¿å­˜æŠ¥å‘Š
with open('emotion_analysis_report.txt', 'w', encoding='utf-8') as f:
    f.write(report)
print("âœ… è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: emotion_analysis_report.txt")

# 7. å¯¼å‡ºç»Ÿè®¡è¡¨æ ¼
summary_table = []
for au in CORE_AU:
    row = {'AU': au}
    for emotion, df in data_dict.items():
        row[f'{emotion}_Mean'] = df[au].mean()
        row[f'{emotion}_SD'] = df[au].std()
    # æ·»åŠ ANOVAç»“æœ
    anova_row = anova_df[anova_df['AU'] == au].iloc[0]
    row['F_statistic'] = anova_row['F_statistic']
    row['p_value'] = anova_row['p_value']
    summary_table.append(row)

summary_df = pd.DataFrame(summary_table)
summary_df.to_csv('au_emotion_statistics.csv', index=False)
print("âœ… ç»Ÿè®¡è¡¨æ ¼å·²ä¿å­˜: au_emotion_statistics.csv")

print("\n" + "=" * 70)
print("ğŸ‰ åˆ†æå®Œæˆï¼")
print("=" * 70)
print("è¾“å‡ºæ–‡ä»¶:")
print("  1. three_emotion_au_analysis.png - ç»¼åˆåˆ†æå›¾è¡¨")
print("  2. emotion_analysis_report.txt - è¯¦ç»†åˆ†ææŠ¥å‘Š")
print("  3. au_emotion_statistics.csv - ç»Ÿè®¡æ•°æ®è¡¨æ ¼")

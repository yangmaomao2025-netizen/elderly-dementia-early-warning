#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‚£è€…-å¯¹ç…§ç»„AUè¡¨æƒ…å¯¹æ¯”åˆ†æž
Patient-Control Group AU Comparison Analysis

å¯¹æ¯”æŠ‘éƒæ‚£è€…ä¸Žå¥åº·å¯¹ç…§ç»„åœ¨æ‚²ä¼¤å’Œç§¯æžæƒ…ç»ªä¸‹çš„AUæ¿€æ´»å·®å¼‚
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from scipy import stats
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['WenQuanYi Zen Hei', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# ============== é…ç½® ==============
# å¯¹ç…§ç»„æ–‡ä»¶ï¼ˆå¥åº·è¢«è¯•ï¼‰
CONTROL_FILES = {
    'sadness': {
        'M1': '/root/.openclaw/media/inbound/file_3---b3314058-964d-470d-8293-13430fdde2c6.csv',
        'M2': '/root/.openclaw/media/inbound/file_4---0dd96eb3-72ff-4ced-a1b8-c5c51fad721a.csv',
        'F1': '/root/.openclaw/media/inbound/file_5---69ad20a2-5a2f-4f18-bdef-056d8c24d515.csv'
    },
    'positive': {
        'M1': '/root/.openclaw/media/inbound/file_21---c1ecbaad-5700-42b7-a743-1b75f81b7ff1.csv',
        'M2': '/root/.openclaw/media/inbound/file_22---772490a5-e791-43b9-8f4a-25c2f614570a.csv',
        'F1': '/root/.openclaw/media/inbound/file_23---06535c58-c474-473b-a68d-aadcee3e3ca7.csv'
    }
}

# æ‚£è€…ç»„æ–‡ä»¶ï¼ˆæŠ‘éƒç—‡æ‚£è€…ï¼‰
PATIENT_FILES = {
    'sadness': {
        'P1': '/root/.openclaw/media/inbound/file_26---2b859f5a-08e2-4713-b654-c56162c1085d.csv'
    },
    'positive': {
        'P1': '/root/.openclaw/media/inbound/file_24---925f9a2e-ba59-4283-829c-75d596785181.csv',
        'P2': '/root/.openclaw/media/inbound/file_25---f701a00a-5efc-44e6-8514-4510879be7a9.csv'
    }
}

# 17ä¸ªæ ¸å¿ƒAU
AU_COLUMNS = ['AU01_r', 'AU02_r', 'AU04_r', 'AU05_r', 'AU06_r', 'AU07_r', 
              'AU09_r', 'AU10_r', 'AU12_r', 'AU14_r', 'AU15_r', 'AU17_r',
              'AU20_r', 'AU23_r', 'AU25_r', 'AU26_r', 'AU45_r']

# æŠ‘éƒç›¸å…³AUæ ‡è®°
DEPRESSION_AUS = ['AU04', 'AU07', 'AU12', 'AU06']  # çš±çœ‰ã€çœ¼ç‘ç´§ç»·ã€å¾®ç¬‘ã€è„¸é¢Šæå‡

# ============== æ•°æ®åŠ è½½å‡½æ•° ==============

def load_au_data(filepath):
    """åŠ è½½AUæ•°æ®æ–‡ä»¶"""
    df = pd.read_csv(filepath)
    df.columns = df.columns.str.strip()
    
    # è¿‡æ»¤ä½Žç½®ä¿¡åº¦å¸§
    df = df[df['confidence'] >= 0.8].copy()
    
    # ç¡®ä¿æ‰€æœ‰AUåˆ—å­˜åœ¨
    for au in AU_COLUMNS:
        if au not in df.columns:
            df[au] = 0.0
    
    return df[AU_COLUMNS].reset_index(drop=True)

def calculate_subject_stats(df):
    """è®¡ç®—å•ä¸ªè¢«è¯•çš„AUç»Ÿè®¡ç‰¹å¾"""
    stats_dict = {}
    for au in AU_COLUMNS:
        stats_dict[f'{au}_mean'] = df[au].mean()
        stats_dict[f'{au}_std'] = df[au].std()
        stats_dict[f'{au}_max'] = df[au].max()
        stats_dict[f'{au}_activation_rate'] = (df[au] > 0.5).mean()
    return stats_dict

# ============== ç»Ÿè®¡åˆ†æžå‡½æ•° ==============

def cohens_d(x1, x2):
    """è®¡ç®—Cohen's dæ•ˆåº”é‡"""
    n1, n2 = len(x1), len(x2)
    s1, s2 = np.var(x1, ddof=1), np.var(x2, ddof=1)
    pooled_std = np.sqrt(((n1-1)*s1 + (n2-1)*s2) / (n1+n2-2))
    return (np.mean(x1) - np.mean(x2)) / pooled_std if pooled_std > 0 else 0

def bootstrap_ci(x1, x2, n_bootstrap=2000, ci=0.95):
    """Bootstrapç½®ä¿¡åŒºé—´"""
    boot_diffs = []
    n1, n2 = len(x1), len(x2)
    
    for _ in range(n_bootstrap):
        boot_x1 = np.random.choice(x1, size=n1, replace=True)
        boot_x2 = np.random.choice(x2, size=n2, replace=True)
        boot_diffs.append(np.mean(boot_x1) - np.mean(boot_x2))
    
    alpha = (1 - ci) / 2
    lower = np.percentile(boot_diffs, alpha * 100)
    upper = np.percentile(boot_diffs, (1 - alpha) * 100)
    return lower, upper

# ============== ä¸»åˆ†æžæµç¨‹ ==============

def main():
    print("="*60)
    print("æ‚£è€…-å¯¹ç…§ç»„AUè¡¨æƒ…å¯¹æ¯”åˆ†æž")
    print("Patient-Control Group Comparison")
    print("="*60)
    
    # åˆ›å»ºç»“æžœç›®å½•
    output_dir = Path('/root/.openclaw/workspace/analysis_results/2026-02-17_æ‚£è€…å¯¹ç…§ç»„å¯¹æ¯”')
    for subdir in ['heatmaps', 'barplots', 'boxplots', 'statistics', 'time_series', 'classifier']:
        (output_dir / subdir).mkdir(parents=True, exist_ok=True)
    
    # ========== 1. åŠ è½½æ‰€æœ‰æ•°æ® ==========
    print("\nðŸ“Š æ­£åœ¨åŠ è½½æ•°æ®...")
    
    all_data = []
    
    # åŠ è½½å¯¹ç…§ç»„æ•°æ®
    for emotion, files in CONTROL_FILES.items():
        for subject, filepath in files.items():
            df = load_au_data(filepath)
            stats_dict = calculate_subject_stats(df)
            stats_dict['subject'] = subject
            stats_dict['group'] = 'Control'
            stats_dict['emotion'] = emotion
            stats_dict['gender'] = 'Male' if subject.startswith('M') else 'Female'
            stats_dict['frames'] = len(df)
            all_data.append(stats_dict)
            print(f"  âœ… Control {subject} ({emotion}): {len(df)} frames")
    
    # åŠ è½½æ‚£è€…ç»„æ•°æ®
    for emotion, files in PATIENT_FILES.items():
        for subject, filepath in files.items():
            df = load_au_data(filepath)
            stats_dict = calculate_subject_stats(df)
            stats_dict['subject'] = subject
            stats_dict['group'] = 'Patient'
            stats_dict['emotion'] = emotion
            stats_dict['gender'] = 'Male'
            stats_dict['frames'] = len(df)
            all_data.append(stats_dict)
            print(f"  âœ… Patient {subject} ({emotion}): {len(df)} frames")
    
    # åˆ›å»ºæ•°æ®æ¡†
    df_all = pd.DataFrame(all_data)
    
    # ========== 2. ç»„é—´æ¯”è¾ƒåˆ†æž ==========
    print("\n" + "="*60)
    print("ðŸ“ˆ ç»„é—´AUæ¿€æ´»å·®å¼‚åˆ†æž (Group Comparison)")
    print("="*60)
    
    comparison_results = []
    
    for emotion in ['sadness', 'positive']:
        print(f"\n--- {emotion.upper()} EMOTION ---")
        
        control_data = df_all[(df_all['group'] == 'Control') & (df_all['emotion'] == emotion)]
        patient_data = df_all[(df_all['group'] == 'Patient') & (df_all['emotion'] == emotion)]
        
        for au in AU_COLUMNS:
            au_mean_col = f'{au}_mean'
            control_values = control_data[au_mean_col].values
            patient_values = patient_data[au_mean_col].values
            
            if len(control_values) > 0 and len(patient_values) > 0:
                # è®¡ç®—å‡å€¼å·®å¼‚
                mean_diff = patient_values.mean() - control_values.mean()
                
                # æ•ˆåº”é‡
                effect_size = cohens_d(patient_values, control_values)
                
                # Bootstrapç½®ä¿¡åŒºé—´
                ci_lower, ci_upper = bootstrap_ci(patient_values, control_values)
                
                # tæ£€éªŒ
                if len(control_values) > 1 and len(patient_values) > 1:
                    t_stat, p_value = stats.ttest_ind(patient_values, control_values)
                else:
                    t_stat, p_value = np.nan, np.nan
                
                comparison_results.append({
                    'emotion': emotion,
                    'AU': au,
                    'control_mean': control_values.mean(),
                    'patient_mean': patient_values.mean(),
                    'mean_diff': mean_diff,
                    'cohens_d': effect_size,
                    'ci_lower': ci_lower,
                    'ci_upper': ci_upper,
                    't_stat': t_stat,
                    'p_value': p_value
                })
                
                # æ‰“å°æ˜¾è‘—ç»“æžœ
                if abs(effect_size) > 0.5:
                    direction = "â†‘" if mean_diff > 0 else "â†“"
                    print(f"  {au}: Patient {direction} Control | d={effect_size:.2f} | p={p_value:.3f}")
    
    df_comparison = pd.DataFrame(comparison_results)
    df_comparison.to_csv(output_dir / 'statistics' / 'group_comparison_stats.csv', index=False)
    print(f"\n  ðŸ’¾ ç»Ÿè®¡ç»“æžœå·²ä¿å­˜è‡³: statistics/group_comparison_stats.csv")
    
    # ========== 3. å¯è§†åŒ– ==========
    print("\n" + "="*60)
    print("ðŸŽ¨ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
    print("="*60)
    
    # 3.1 ç»„é—´å·®å¼‚çƒ­å›¾
    fig, axes = plt.subplots(1, 2, figsize=(14, 8))
    
    for idx, emotion in enumerate(['sadness', 'positive']):
        emotion_data = df_comparison[df_comparison['emotion'] == emotion]
        pivot_data = emotion_data.pivot(index='AU', columns='emotion', values='cohens_d')
        
        sns.heatmap(pivot_data, annot=True, fmt='.2f', cmap='RdBu_r', 
                   center=0, vmin=-2, vmax=2, ax=axes[idx], cbar_kws={'label': "Cohen's d"})
        axes[idx].set_title(f'{emotion.capitalize()} Emotion: Patient vs Control\n(Effect Size)', fontsize=12)
        axes[idx].set_xlabel('')
    
    plt.tight_layout()
    plt.savefig(output_dir / 'heatmaps' / 'patient_control_effect_size_heatmap.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("  âœ… æ•ˆåº”é‡çƒ­å›¾å·²ç”Ÿæˆ")
    
    # 3.2 æŠ‘éƒç›¸å…³AUçš„ç®±çº¿å›¾
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    axes = axes.flatten()
    
    for idx, au_base in enumerate(DEPRESSION_AUS):
        au_col = f'{au_base}_r_mean'
        
        plot_data = []
        labels = []
        colors = []
        
        for emotion in ['sadness', 'positive']:
            control_vals = df_all[(df_all['group'] == 'Control') & 
                                 (df_all['emotion'] == emotion)][au_col].values
            patient_vals = df_all[(df_all['group'] == 'Patient') & 
                                 (df_all['emotion'] == emotion)][au_col].values
            
            plot_data.extend([control_vals, patient_vals])
            labels.extend([f'Control\n({emotion})', f'Patient\n({emotion})'])
            colors.extend(['lightblue', 'salmon'])
        
        bp = axes[idx].boxplot(plot_data, labels=labels, patch_artist=True)
        for patch, color in zip(bp['boxes'], colors):
            patch.set_facecolor(color)
        
        axes[idx].set_title(f'{au_base} Activation', fontsize=11)
        axes[idx].set_ylabel('Mean Intensity')
        axes[idx].tick_params(axis='x', rotation=45)
        axes[idx].grid(axis='y', alpha=0.3)
    
    plt.suptitle('Key Depression-Related AU: Patient vs Control', fontsize=14, y=1.02)
    plt.tight_layout()
    plt.savefig(output_dir / 'boxplots' / 'depression_au_boxplots.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("  âœ… æŠ‘éƒç›¸å…³AUç®±çº¿å›¾å·²ç”Ÿæˆ")
    
    # 3.3 AUæ¿€æ´»æ°´å¹³å¯¹æ¯”æŸ±çŠ¶å›¾
    fig, axes = plt.subplots(1, 2, figsize=(14, 6))
    
    for idx, emotion in enumerate(['sadness', 'positive']):
        emotion_data = df_comparison[df_comparison['emotion'] == emotion].copy()
        emotion_data = emotion_data.sort_values('cohens_d', key=abs, ascending=False).head(10)
        
        colors = ['red' if x > 0 else 'blue' for x in emotion_data['cohens_d']]
        axes[idx].barh(range(len(emotion_data)), emotion_data['cohens_d'], color=colors, alpha=0.7)
        axes[idx].set_yticks(range(len(emotion_data)))
        axes[idx].set_yticklabels(emotion_data['AU'])
        axes[idx].set_xlabel("Cohen's d (Patient - Control)")
        axes[idx].set_title(f'{emotion.capitalize()}: Top 10 AU Differences')
        axes[idx].axvline(x=0, color='black', linestyle='-', linewidth=0.5)
        axes[idx].axvline(x=0.5, color='gray', linestyle='--', alpha=0.5, label='Medium Effect')
        axes[idx].axvline(x=-0.5, color='gray', linestyle='--', alpha=0.5)
        axes[idx].grid(axis='x', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(output_dir / 'barplots' / 'top_au_differences.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("  âœ… AUå·®å¼‚æŸ±çŠ¶å›¾å·²ç”Ÿæˆ")
    
    # ========== 4. åˆ†ç±»å™¨åˆ†æž ==========
    print("\n" + "="*60)
    print("ðŸ¤– ç®€å•åˆ†ç±»æ¨¡åž‹ (æ‚£è€… vs å¯¹ç…§)")
    print("="*60)
    
    # å‡†å¤‡ç‰¹å¾çŸ©é˜µ
    feature_cols = [f'{au}_mean' for au in AU_COLUMNS]
    
    X = df_all[feature_cols].values
    y = (df_all['group'] == 'Patient').astype(int).values
    emotions = df_all['emotion'].values
    
    # æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # é€»è¾‘å›žå½’
    print("\n--- Logistic Regression ---")
    lr = LogisticRegression(random_state=42, max_iter=1000)
    lr_scores = cross_val_score(lr, X_scaled, y, cv=3)
    print(f"  Cross-validation accuracy: {lr_scores.mean():.3f} (+/- {lr_scores.std()*2:.3f})")
    
    # è®­ç»ƒå®Œæ•´æ¨¡åž‹
    lr.fit(X_scaled, y)
    
    # ç‰¹å¾é‡è¦æ€§
    feature_importance = pd.DataFrame({
        'AU': AU_COLUMNS,
        'coefficient': lr.coef_[0]
    }).sort_values('coefficient', key=abs, ascending=False)
    
    print("\n  æœ€é‡è¦çš„é¢„æµ‹ç‰¹å¾ (Top 5):")
    for _, row in feature_importance.head(5).iterrows():
        direction = "é¢„æµ‹æ‚£è€…" if row['coefficient'] > 0 else "é¢„æµ‹å¯¹ç…§"
        print(f"    {row['AU']}: {row['coefficient']:.3f} ({direction})")
    
    # éšæœºæ£®æž—
    print("\n--- Random Forest ---")
    rf = RandomForestClassifier(n_estimators=100, random_state=42)
    rf_scores = cross_val_score(rf, X_scaled, y, cv=3)
    print(f"  Cross-validation accuracy: {rf_scores.mean():.3f} (+/- {rf_scores.std()*2:.3f})")
    
    rf.fit(X_scaled, y)
    rf_importance = pd.DataFrame({
        'AU': AU_COLUMNS,
        'importance': rf.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print("\n  ç‰¹å¾é‡è¦æ€§ (Top 5):")
    for _, row in rf_importance.head(5).iterrows():
        print(f"    {row['AU']}: {row['importance']:.3f}")
    
    # ä¿å­˜åˆ†ç±»å™¨ç»“æžœ
    feature_importance.to_csv(output_dir / 'classifier' / 'logistic_regression_features.csv', index=False)
    rf_importance.to_csv(output_dir / 'classifier' / 'random_forest_importance.csv', index=False)
    
    # ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾
    fig, axes = plt.subplots(1, 2, figsize=(14, 6))
    
    # é€»è¾‘å›žå½’ç³»æ•°
    colors = ['red' if x > 0 else 'blue' for x in feature_importance['coefficient']]
    axes[0].barh(range(len(feature_importance)), feature_importance['coefficient'], color=colors, alpha=0.7)
    axes[0].set_yticks(range(len(feature_importance)))
    axes[0].set_yticklabels(feature_importance['AU'])
    axes[0].set_xlabel('Coefficient')
    axes[0].set_title('Logistic Regression: AU Predictive Power')
    axes[0].axvline(x=0, color='black', linewidth=0.5)
    axes[0].grid(axis='x', alpha=0.3)
    
    # éšæœºæ£®æž—é‡è¦æ€§
    axes[1].barh(range(len(rf_importance)), rf_importance['importance'], color='green', alpha=0.7)
    axes[1].set_yticks(range(len(rf_importance)))
    axes[1].set_yticklabels(rf_importance['AU'])
    axes[1].set_xlabel('Feature Importance')
    axes[1].set_title('Random Forest: AU Feature Importance')
    axes[1].grid(axis='x', alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(output_dir / 'classifier' / 'feature_importance.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("  âœ… åˆ†ç±»å™¨ç‰¹å¾é‡è¦æ€§å›¾å·²ç”Ÿæˆ")
    
    # ========== 5. ç”Ÿæˆç»¼åˆæŠ¥å‘Š ==========
    print("\n" + "="*60)
    print("ðŸ“ ç”Ÿæˆç»¼åˆæŠ¥å‘Š")
    print("="*60)
    
    report_lines = []
    report_lines.append("# æ‚£è€…-å¯¹ç…§ç»„AUè¡¨æƒ…å¯¹æ¯”åˆ†æžæŠ¥å‘Š")
    report_lines.append(f"\nç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}")
    report_lines.append("\n" + "="*60)
    
    # æ ·æœ¬ä¿¡æ¯
    report_lines.append("\n## 1. æ ·æœ¬ä¿¡æ¯")
    report_lines.append(f"- å¯¹ç…§ç»„: 3äºº (2ç”·1å¥³)")
    report_lines.append(f"- æ‚£è€…ç»„: 3äºº (3ç”·)")
    report_lines.append(f"- æƒ…ç»ªç±»åž‹: æ‚²ä¼¤ã€ç§¯æž")
    
    # å…³é”®å‘çŽ°
    report_lines.append("\n## 2. å…³é”®å‘çŽ°")
    
    # æ‚²ä¼¤æƒ…ç»ªå·®å¼‚
    sadness_sig = df_comparison[(df_comparison['emotion'] == 'sadness') & 
                                (abs(df_comparison['cohens_d']) > 0.5)]
    if len(sadness_sig) > 0:
        report_lines.append(f"\n### æ‚²ä¼¤æƒ…ç»ªæ˜¾è‘—å·®å¼‚ AU (|d| > 0.5):")
        for _, row in sadness_sig.iterrows():
            direction = "æ‚£è€… > å¯¹ç…§" if row['cohens_d'] > 0 else "æ‚£è€… < å¯¹ç…§"
            report_lines.append(f"- {row['AU']}: Cohen's d = {row['cohens_d']:.2f} ({direction})")
    
    # ç§¯æžæƒ…ç»ªå·®å¼‚
    positive_sig = df_comparison[(df_comparison['emotion'] == 'positive') & 
                                 (abs(df_comparison['cohens_d']) > 0.5)]
    if len(positive_sig) > 0:
        report_lines.append(f"\n### ç§¯æžæƒ…ç»ªæ˜¾è‘—å·®å¼‚ AU (|d| > 0.5):")
        for _, row in positive_sig.iterrows():
            direction = "æ‚£è€… > å¯¹ç…§" if row['cohens_d'] > 0 else "æ‚£è€… < å¯¹ç…§"
            report_lines.append(f"- {row['AU']}: Cohen's d = {row['cohens_d']:.2f} ({direction})")
    
    # åˆ†ç±»å™¨æ€§èƒ½
    report_lines.append(f"\n## 3. åˆ†ç±»æ¨¡åž‹æ€§èƒ½")
    report_lines.append(f"- é€»è¾‘å›žå½’å‡†ç¡®çŽ‡: {lr_scores.mean():.3f} (Â±{lr_scores.std():.3f})")
    report_lines.append(f"- éšæœºæ£®æž—å‡†ç¡®çŽ‡: {rf_scores.mean():.3f} (Â±{rf_scores.std():.3f})")
    
    report_lines.append(f"\n### æœ€é‡è¦çš„åˆ†ç±»ç‰¹å¾:")
    for _, row in rf_importance.head(3).iterrows():
        report_lines.append(f"- {row['AU']}: {row['importance']:.3f}")
    
    # ä¿å­˜æŠ¥å‘Š
    report_text = '\n'.join(report_lines)
    with open(output_dir / 'statistics' / 'comparison_report.md', 'w', encoding='utf-8') as f:
        f.write(report_text)
    
    print(report_text)
    print(f"\n  ðŸ’¾ æŠ¥å‘Šå·²ä¿å­˜è‡³: statistics/comparison_report.md")
    
    print("\n" + "="*60)
    print(f"âœ… åˆ†æžå®Œæˆï¼æ‰€æœ‰ç»“æžœä¿å­˜åœ¨: {output_dir}")
    print("="*60)

if __name__ == '__main__':
    main()
